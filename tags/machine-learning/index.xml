<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>machine learning on Philosophical Hacker</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in machine learning on Philosophical Hacker</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 01 Sep 2019 08:50:00 -0400</lastBuildDate>
    
        <atom:link href="https://www.philosophicalhacker.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>An Intro to Gradient Descent for Kotlin Programmers</title>
      <link>https://www.philosophicalhacker.com/post/gradient-descent-for-kotlin-programmers/</link>
      <pubDate>Sun, 01 Sep 2019 08:50:00 -0400</pubDate>
      
      <guid>https://www.philosophicalhacker.com/post/gradient-descent-for-kotlin-programmers/</guid>
      <description>Introduction Gradient descent is an algorithm that&amp;rsquo;s used to solve supervised learning and deep learning problems. Here I&amp;rsquo;m going to try to give you an idea of why the algorithm works and how you&amp;rsquo;d implement it in Kotlin. I&amp;rsquo;ll also show the algorithm working with a simple kaggle dataset involving video game sales and ratings.
Everything I cover here is covered in Andrew Ng&amp;rsquo;s excellent Coursera machine learning course with the exception of the Kotlin implementation of gradient descent.</description>
      
    </item>
    
  </channel>
</rss>
