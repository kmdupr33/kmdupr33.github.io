<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.57.2" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Some problems with the impossibility of achieving OKRs&nbsp;&ndash;&nbsp;Philosophical Hacker</title><link rel="stylesheet" href="/css/core.min.23e33545b91049b616ac4ba673cc5ec6dd32e3023e7f08dbbeef7202014a10af6bd328c6400a99dc5f681b085a7bb8bf.css" integrity="sha384-I&#43;M1RbkQSbYWrEumc8xext0y4wI&#43;fwjbvu9yAgFKEK9r0yjGQAqZ3F9oGwhae7i/">
<script type="text/javascript">
  window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=document.createElement("script");r.type="text/javascript",r.async=!0,r.src="https://cdn.heapanalytics.com/js/heap-"+e+".js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(r,a);for(var n=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","resetIdentity","removeEventProperty","setEventProperties","track","unsetEventProperty"],o=0;o<p.length;o++)heap[p[o]]=n(p[o])};
  heap.load("2872977926");
</script>
<body>
    <div class="base-body"><section id="header" class="site header max-body-width">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">Philosophical Hacker</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/about/me">About</a><a class="nav item" href="/talk">Talks</a><a class="nav item" href="https://www.oreilly.com/programming/free/rxjava-for-android-app-development.csp?intcmp=il-prog-free-product-na_new_site_rxjava_for_android_app_development"target="_blank">RxJava O&#39;Reilly Book</a><a class="nav item" href="/note">Notes</a></nav></div></span></div></section><div id="content" class="max-body-width"><section class="article header">
    <h1 class="article title">Some problems with the impossibility of achieving OKRs</h1><p class="article date">2019-03-01</p></section><article class="article markdown-body">

<p>In many ways, OKRs are a neat way of structuring goals for a company. According to Marty Cagan, product managers should be especially interested in OKRs as a goal setting framework since they are a better way of tracking product work than a &ldquo;product roadmap.&rdquo; I agree with Cagan. OKRs are often better than typical product road maps.</p>

<p>However, there’s an aspect of OKRs that I think is morally and psychologically problematic: the idea that OKRs should be impossible to entirely achieve. Let’s call this aspect of OKRs the “the impossibility prescription.”</p>

<p>In this article, I discuss some of the moral and psychological problems with the impossibility prescription and comment on how it affects the viability of OKRs as an alternative to product road maps and as a corporate goal setting framework. In the first section, I trace the idea of OKRs back to the original source, Andy Grove’s High Output Management. Next, I argue that Grove’s reasoning for making OKRs impossible to entirely achieve is often manipulative and morally problematic, unless companies can secure the consent of employees. In the final section, I argue that some of the claims underlying the impossibility prescription rest on dubious psychology.</p>

<h3 id="the-history-of-impossible-krs">The History of Impossible KRs</h3>

<p>OKRs — both <a href="https://www.amazon.com/dp/B015VACHOK/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">in Andy Grove’s original introductory text</a> and <a href="https://www.amazon.com/dp/B078FZ9SYB/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">in John Doerr’s more recent book</a> — are supposed to be impossible to entirely achieve. The logic behind this traces back to a few passages in Andy Grove’s High Output Management.</p>

<p>The idea falls out of Grove&rsquo;s theory of motivation. Grove says,</p>

<blockquote>
<p>&ldquo;A need once satisfied stops being a need and therefore stops being a source of motivation&hellip;if we are to create and maintain a high degree of motivation, we must keep some need unsatisfied at all times.&rdquo;<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup></p>
</blockquote>

<p>Leaning heavily on Maslow&rsquo;s hierarchy of needs, Grove then proceeds to note how all levels of need can eventually be met and therefore no longer serve as a source of motivation. This is true for all needs except for our need for self-actualization. People after self-actualization, according to Grove, will &ldquo;spontaneously try to test the outer limits of their abilities,&rdquo; but &ldquo;when the need to stretch is not spontaneous, management needs to create an environment to foster it.&rdquo;<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup> Finally, he arrives at the conclusion we&rsquo;re interested in when he says,</p>

<blockquote>
<p>“In an MBO system [MBO was HP’s precursor to OKRs]…objectives should be set at a point high enough so that even if the individual pushes himself hard, he will still only have a fifty-fifty chance of making them.&rdquo;<sup class="footnote-ref" id="fnref:3"><a href="#fn:3">3</a></sup></p>
</blockquote>

<h3 id="moral-problems">Moral Problems</h3>

<p>Let&rsquo;s talk about what&rsquo;s morally unsettling about this. The problem here is not about work-life balance. (I&rsquo;m actually pretty skeptical of how much weight is put on the importance of that balance these days.) The moral problem is actually about consent and respect. There&rsquo;s nowhere in my job contract that says that I&rsquo;m signing up for my employer to leverage my need for self-actualization for shareholder profit. I&rsquo;d object to such a clause, especially if my employer tried this by using goals whose difficulties are artificially inflated.</p>

<p>Now, I recognize that employee benefit vs. company benefit doesn&rsquo;t have to be zero-sum, but remember: in this particular case, we&rsquo;re talking about people who aren&rsquo;t motivated to &ldquo;stretch.&rdquo; So, in this case, the game becomes zero-sum; the employee is pushed to favor the company&rsquo;s interests. Since the game is zero-sum for certain individuals, their consent matters. One way of securing that consent would be for companies to make deeper commitments to the well-being of their employees, and maybe when Grove wrote this, this deeper commitment was implicit.</p>

<p>However, as I read it in today, it seems like a corporate power-grab without corresponding assumption of responsibility. This impression is mostly driven by recent books and articles about the lack of investment in human capital in businesses in general (e.g., <a href="https://www.nytimes.com/2017/09/03/upshot/to-understand-rising-inequality-consider-the-janitors-at-two-top-companies-then-and-now.html">this NYT article</a>) and about the dysfunctional way silicon valley in particular treats it’s people (e.g., <a href="https://www.amazon.com/dp/B07B2T6R8Q/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">Lab Rats</a> and <a href="https://disruption.medium.com/">Medium’s The Big Disruption</a>). Insofar as these accusations against contemporary businesses are fair, I’d like to suggest that if you buy Grove’s psychology behind the impossibility of OKRs and you’re tapping that deeply into what makes us human (the need for self-actualization) to drive your business, you better be damn sure you that you’re treating your employees like proper humans. In the current context, I don’t think it’s moral or prudent to adopt Grove’s way of thinking without first considering whether your company is investing sufficiently in it’s people.<sup class="footnote-ref" id="fnref:4"><a href="#fn:4">4</a></sup></p>

<h3 id="dubious-psychology">Dubious Psychology</h3>

<p>Let’s say we ignore the above moral problem for a second. Are people motivated by goals they know they cannot entirely achieve? It’s not at all clear that the answer to this question is “yes.”</p>

<p>Anecdotally, I’ve talked with several people who think impossibility prescription for OKRs is a bad joke. Intuitively, this makes sense to me. Why strive for a goal that you know you can’t achieve?</p>

<p>There are some studies, moreover, that suggest that impossible goals are demotivating.</p>

<p>A study cited in Peopleware, for example, found that teams working in software without estimates tend to perform better than teams with estimates. The explanation offered by the authors was that estimates are often wrong, and once people know that they aren’t going to meet their estimates, they aren’t very motivated to work hard since they know they won’t be able to meet their estimate.<sup class="footnote-ref" id="fnref:5"><a href="#fn:5">5</a></sup></p>

<p>There’s also a collection of studies cited by the author of the HBR article “The Folly of Stretch Goals.” Those studies also challenge the idea that big, challenging seeming goals are the way to motivate employees.</p>

<h3 id="conclusion">Conclusion</h3>

<p>So, if we look at the reasoning behind the impossibility of achieving OKRs, we find two problems. The first problem is that Grove’s appropriation of Maslow’s idea of self-actualization may not actually be psychologically plausible. In other words, it’s not clear that setting impossibly high goals will actually tap into employee’s needs for self-actualization. Even if we take Grove’s psychology seriously, we run into the second (moral) problem, which is that attempting to leverage employee’s need for self-actualization to get them to chase after impossible goals is manipulative.</p>

<p>Where does this leave us as product managers and corporate leaders? Overall, OKRs are a fine way of setting goals for products and for companies. I just think we should probably drop the idea that key results should be impossible to entirely achieve.</p>

<hr />

<h3 id="notes">Notes</h3>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">Andy Grove, <em>High Output Management</em>, 156.
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2">Ibid., 165.
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
<li id="fn:3">Ibid.
 <a class="footnote-return" href="#fnref:3"><sup>[return]</sup></a></li>
<li id="fn:4">Defenders of OKRs might jump in here and try to object by saying that employees who do well on their OKRs will be rewarded, so there’s nothing morally amiss about setting the OKRs so that there’s only a <sup>50</sup>&frasl;<sub>50</sub> chance of success. This objection won’t work because typically OKRs are not at all tied to compensation precisely because leaders want to preserve the impossibility of achieving all OKRs perfectly. If compensation is tied to OKR performance, leaders worry that employees will to try to game OKRs and lower the bar so they can get a raise or bonus.
 <a class="footnote-return" href="#fnref:4"><sup>[return]</sup></a></li>
<li id="fn:5">Tom Demarco and Timothy Delister, <em>Peopleware</em>, 44.
 <a class="footnote-return" href="#fnref:5"><sup>[return]</sup></a></li>
</ol>
</div>
</article><section class="article labels"><a class="article tag" href=/tags/startups/>startups</a><a class="article tag" href=/tags/business/>business</a><a class="article tag" href=/tags/io-psychology/>io psychology</a><a class="article tag" href=/tags/product-management/>product management</a></section><section class="article navigation"><p><a class="link" href="/post/big-disruption-review/"><span class="li"></span>Hilarious Heresy: A Review of Jessica Powell’s "The Big Disruption"</a></p><p><a class="link" href="/post/how-lean-became-profound/"><span class="li"></span>How The Lean Principle Became Profound</a class="link">
    </p></section><section class="article discussion"><div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "philosophicalhacker" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a></section></div><section id="footer" class="footer max-body-width"><div
  style="display:flex; flex-direction:row; flex-wrap:wrap; justify-content:space-between;"
>
  <p style="flex-shrink: 0;">&copy; 2020 Matt Dupree
  </p>
</div>
</section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-63544399-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
</div>
</body>

</html>