<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.125.7"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Libraries are under-used. LLMs make this problem worse.&nbsp;&ndash;&nbsp;Philosophical Hacker</title><link rel="stylesheet" href="/css/core.min.63f706677e61b4ee62b8daf083358d3bbf8ac8ab03c7d171af3180fab3a3ebb83efb79fb98674f13dde6db11de2bf694.css" integrity="sha384-Y/cGZ35htO5iuNrwgzWNO7&#43;KyKsDx9FxrzGA&#43;rOj67g&#43;&#43;3n7mGdPE93m2xHeK/aU"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Libraries are under-used. LLMs make this problem worse." />
<script type="text/javascript">
  window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=document.createElement("script");r.type="text/javascript",r.async=!0,r.src="https://cdn.heapanalytics.com/js/heap-"+e+".js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(r,a);for(var n=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","resetIdentity","removeEventProperty","setEventProperties","track","unsetEventProperty"],o=0;o<p.length;o++)heap[p[o]]=n(p[o])};
  heap.load("2872977926");
</script>
<script type="application/javascript">
  (function(b,o,n,g,s,r,c){if(b[s])return;b[s]={};b[s].scriptToken="Xy0yMDEzNTMyMTI3";b[s].callsQueue=[];b[s].api=function(){b[s].callsQueue.push(arguments);};r=o.createElement(n);c=o.getElementsByTagName(n)[0];r.async=1;r.src=g;r.id=s+n;c.parentNode.insertBefore(r,c);})(window,document,"script","https://cdn.oribi.io/Xy0yMDEzNTMyMTI3/oribi.js","ORIBI");
</script>


<link rel="canonical" href="https://makefizz.buzz/posts/libraries-llms"/>
<body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">Philosophical Hacker</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/talk">Talks</a><a class="nav item" href="https://www%2eoreilly%2ecom/programming/free/rxjava-for-android-app-development%2ecsp?intcmp=il-prog-free-product-na_new_site_rxjava_for_android_app_development"target="_blank" rel="noopener noreferrer">RxJava O&#39;Reilly Book</a><a class="nav item" href="/note">Notes</a></nav></div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Libraries are under-used. LLMs make this problem worse.</h1><p class="article date">2025-07-30<span class="reading-time"> â€¢ 2 minutes to read</span></p></section><article class="article markdown-body"><p>Libraries are under-used. Why? Briefly:</p>
<ol>
<li>Writing code is more fun than reading documentation.</li>
<li>We tend to understimate the complexity of problems we don&rsquo;t understand well, so we undervalue libraries that solve these poorly understood problems.</li>
<li>Perverse incentives: libraries compete with big internal engineering projects that look good in a promo packet.</li>
</ol>
<p>LLMs make this problem worse. Why? Less briefly:</p>
<p>Vibe coding is more fun than reading documentation. Shit, vibe-coding can be more fun than ordinary coding. You write a small prompt, get a ton of output, and get to revel in how long writing all of that code manually would have taken. You get to feel like we&rsquo;re on the cusp of a new era.</p>
<p>The problem is that the LLM&rsquo;s output just isn&rsquo;t as good as a battle-tested library. As we all know, LLMs don&rsquo;t follow our prompts perfectly, but even if they did, our prompts comes from our niave view of our problems. Niave prompt in, niave code out.</p>
<p>By contrast, library creators know the problem better than us. They have better prompts and the experience to shape an LLM&rsquo;s output into solid library code. For many complex problems, we should use their library, not an LLM directly.</p>
<p>Perverse incentives push us the wrong way here too. An engineer who uses an LLM to generate thousands of lines of code is a innovative leader who will help the company win in the new age of AI. &ldquo;Promote them!,&rdquo; the managers say. I&rsquo;m not saying that engineers consciously choose to use LLMs over libraries because of the hype. Just saying the incentives are there.</p>
</article>
</div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/post/llm-proofing-our-takehome/"><span class="iconfont icon-article"></span>LLM Proofing Our Takehome Challenge</a></p></section></div></section><section id="footer"><div style="display: flex; flex-direction: row; justify-content: center;">
  <p>
    &copy; 2025 Matt Dupree
  </p>
</div>
</section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script><script src="/js/core.min.38b060a751ac96384cd9327eb1b1e36a21fdb71114be07434c0cc7bf63f6e1da274edebfe76f65fbd51ad2f14898b95b.js" integrity="sha384-OLBgp1GsljhM2TJ&#43;sbHjaiH9txEUvgdDTAzHv2P24donTt6/529l&#43;9Ua0vFImLlb"></script></body>

</html>